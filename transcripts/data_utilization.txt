 Yeah, let's try that. I have some problems with my camera, so I can't join. You don't have to see me today. But I invited for this meeting, so great for all of us to join. We will see the results from this, the outcome where we will be. But from my perspective, me and Cheryl has been talking quite a lot on data in our meetings. We have regular meetings, me and Cheryl talking about automation and what is happening all over Skanje. And specifically, we are supporting M-A in the battery factory, their project where they're a bit backwards. They're working. They are to recruit, I think it's three automation engineers, so they don't know what they should do. So now we have a project to try to identify what they would work with. Yeah, a bit backwards. But then there is a lot of talk about data that they collect a lot later. And data is good, but we need to use data. And then the data becomes value for us. I think that's kind of the background. And then I know you, who stayed up for some time, has worked with this area. Maybe Mathias will pick over a bit. I don't know exactly. But how do we spread what you do in DE and other units all over Skanje, really, to try to make us use data as well? Yeah. That's kind of the background. I think, Shana, you can definitely go into more details. But what do you think from the lab perspective, what do you learn on this brief introduction? Yes, so there are, I think, a list of things you have touched upon. Let's take them one by one. First of all, there will be three automation engineers, or let's say, DEA, that they will be hired at ME, right, the battery factory. And in these three people, this competence about data will lie also within them. So that's also the idea that some of them will work with data, or we're trying to figure that out. I don't know if they know what they should do. But I know they have one guy now working with data at ME. But I think he's working most to S26. Yes, because, of course, you can subdivide a little bit the work in the area of data in different parts. One would be like the collection of data. So making sure that your equipment is generating data in a good format, in a good quality, and that provides the value, or in a way that you can later use it to create value, right? And that involves just building connections to the robots, maintaining these connections, troubleshooting stuff, maintaining databases, and stuff like that. Later on, once this data is available to be accessed, you will have usually this role of data engineer, so to say. It is a person that supports in moving the data between places and transforming the data. So what is happening is you have now a lot of data that is static, has been collected from the machines. And this person helps format the data in the way that later the consumers will use it. And then that brings us to the consuming side. On the consuming side, usually you start with analytics. That is maybe people that are just trying to understand things behind this data. And you can start by just understanding what are the diagnostics of your equipment. But you can also try to understand a little bit of your build dashboards, visualize information, and support the other teams. And the next step after that would be prescribing or predicting in the future. So you have some data sets and some information. And this has some type of patterns that we can analyze. And it tells us that if we continue like this, this machine will break down over time, for example. Right? So you have different areas or competences. And usually it's very difficult. So there are some people that are able to do all of these steps. But that is not so common. Usually you have people that are very good close to the hardware. There are people that are very good in all of this transformation of data, maintaining databases and making data available. And then there's people that are very good at the analytics part and potentially the next step to predicting that it's a machine learning. Okay. So that is a little bit of a summary of possible competences. Then you also mentioned that we need to understand what type of data or what we should use it for. And that maybe we're working backwards because we are hiring a person before we know what person is going to do. So there is two ways you can work with this, with data in general. One is like if we make like an analogy to the way we would cook. One is like we have a recipe and then we know what ingredients go in the recipe. We go into our fridge, we take out the ingredients and then we cook something. The alternative is we can go into our fridge directly. We open our fridge up. We see what's inside the fridge and based on the ingredients are there, then we build our dinner or lunch or something like that. So there is two ways, right? In this instance, it feels a little bit like we are looking directly into the fridge and seeing what's there. Right? So the idea here is that we are having some data and now that we have the data, we're trying to find out what we can do with it. It feels a little bit like that's what the battery factory is doing, right? Or like where the state is right now. And that is one process that is common with datasets. And it can be complemented with, you know, there exist these things that we have done at TE or at DX. They're doing some other things or some other places. Let's try to see what they are using data for and try to also build the same thing in the battery. So then this would be the opposite way. We have some recipes and we try to use the ingredients to build these recipes. But I said those are a little bit my comments so far. And now the third part, like you mentioned, Frelik, was, oh, and how can we promote the thing that has been already done with an DE and what is it that has been done at TE? So and other places. So then I can give you or are there any questions so far for comments before I go into this part? I have a lot of comments, but we can tell you later. Cool. So I think one comment from my part is I think it sounds great. And I think this last point is really and I mean, it's kind of the thousand ten thousand dollar question. How do we learn from one peer you have spread it to the other ones? Not necessarily only ME. Yes. Yeah. So it is a bit difficult and there is not the I don't have the million dollar answer. Right. So we are trying to we have been trying I started one a little bit less than a year ago trying to answer a little bit of this question. Right. Each unit is doing a little bit their own thing. Then we also have IT organization and other business units are even doing some other things. And each is a little bit on their own. So to say how can we and we from the lab, what we have been doing in the past is building dashboards in the area of Internet of Things or IOT, connecting devices and bringing data into databases. So the hardware side and later solving data questions from customers. So for example, an example of this is permortin son comes to us and says, oh, our colleagues in Lulu have this problem about, you know, they're going to maybe expand their storage, but they have no idea of the utilization of their warehouse right now. Can you help us understand from this data? We already have if we can extract some valuable information inside from it or if we need to extract some more data and then we support with that case. And this type of small cases or small cases, the last one or two months, we have had several of those across different units. So then we came to a point where we say, OK, can we try to not only work on these small cases, we try to complement it with like, you know, we look at a complete line, we try to analyze how the line works, how the people interact with information, what information is there, what information is missing and try to generalize some results that can be copy pasted to different units or different production lines. So then we started this project called Data Driven Production Line. There was a it's a little bit exploratory, so to say. So there was no defined or exact defined outcome like, oh, we're going to improve the OPE by 10 percent. No, it was first stage. Let's understand the line. Let's understand the stakeholders, what systems are available, what data is available and what can we do with it? What are we already doing with it? What do we need to increase and so on? We did that between September and the end of January, we had some results and we came with four. We found out four things and we did this through intensive interviews with all the people in the line through observation. Just go in there and see there and then through a bit of analysis of the systems they have. Just looking at EBA and DRIK and the information they display. And we found four categories that are interesting. One, the first one is what we called digital productivity. It is in the area of so a lot of people we talked, everyone says we are using at least five to ten different systems to mobilize our information or data. So let's say we go to the line in the morning, we write things down in a notebook, we bring this notebook information or data into Excel. It's Excel. Then we put it in some database or whatever and we send it through teams. Someone receives it in teams, you know, and then you're jumping data from one database or from one data source to another, one system to another. And we also do that ourselves. Probably you, Shell and you, Freddie, you have also similar things. And so this category called digital productivity was about can we find systems that support us in this collaboration and in this data transfer? Can we build things or automation bots or whatever that transfer this information automatically for us? OK, so that was the first category. The second category was competence or, you know, competency in data. And this is about, you know, many people say, oh, we would love to do a little bit more here, but we don't really have the analytics competence. We don't now have anyone that knows machine learning or we don't have I don't know how to use macros in Excel or whatever it is that you need to do the job that you want done. So the second one, and we said that is something that, you know, potentially the steering group of D.E. in this instance needs to work with and try to build this competence and, you know, promote people going to this kind of courses and so on. And then we have the last two categories that were we called them. Data. I don't remember now, but like data driven and the fourth was line health and data driven is about building like this culture of data that we all know what a good quality data is, that we have access to data, that we have responsible people that we can talk to if we need access to data, that someone is maintaining the databases and that all of this is transparent and that we know, you know, who will do this? How can we transfer it to that? And we understand if we have a problem in the line, how to handle it or like how to work on this data set, what type of things we need to collect. And the last one called line health is a little bit an application of this data driven that is a bit more long term in creating this culture, but on a day to day basis. So like how do our operators interact with the systems? What is our way of troubleshooting using data? How can we bring data to meetings and information? And it's a little bit what we have been focusing on now in the second phase of this project. So we now want to, we found out these four big categories that are a bit generalizable. I think that almost every unit will have a little bit similar to this. Now we want to work a little bit of this line health. And the idea there is that we maybe tackle some specific problems or some specific cases. We do a data driven approach, like we collect the data, we visualize it, we highlight if something is missing, and then we present some results of what happened. And then potentially from there, we can extract something that is generalizable and how at least the method of how you would do this and then present it to other units as well. So this is maybe how you could handle this type of thing or this type of other thing and so on. And that is where we are right now. And sorry for talking so much, but that is a little bit information. But is that from the DV line, the new base assembler line? Yes, exactly. So do you take data from the press units and the robots and all the equipment or what kind of tools do you? So what we have done is try to, so we always wanted to give like the ownership and the decision making in this project so they should decide what is important to work on. So we generally just tackled the biggest problems. The problems are causing more and more stops. And we have found that have something to do with data. So that's something that we can work today with data sets. So we're doing three cases. One is about their AGVs and their stop time that the AGVs had because of X reasons. So doing an analysis about that and making it available for workers. The second one is the RGVs. So the rail guide vehicles. The thing there is that they are not collecting any data at all. And the idea is to bring it to the same level as the AGVs. So start collecting data, start visualizing it. And the third case is about stops that occur because of drying of silicone and stop time. So they need to find an optimal waiting time that is called to move fast forward so that the silicone is dry enough, but not too dry. But that doesn't cause stop times. So three small cases that our colleagues from DIGI are working on and we're supporting. And it's a little bit what we will showcase there. And on top of that, we will do some type of line mapping. So let's say we will look at the whole line and do some type of color coding on where each station is in, say, data maturity and also how much we can do in that station. So let's say there is a lot of stops caused by a station and we have data to work on. Maybe we can color that yellow. That means that we can start working with it or whatever. There's another station that proves a lot of stop. We don't have any data, but we could solve it by using some data analytics. Maybe that's red. Green is something that's working well or whatever. We are still working on how we will do that. But the idea is that then the unit can build some type of roadmap on what to tackle next, where to put their efforts and their competences on. So it's connected to the PLC for the conveyor system, for instance, or is it to Scala system, DIGI, or what kind of system do you take data from? So it can be any, honestly, we don't really mind. We don't really care about the system. So it would depend on each station. So some stations have, for example, at the NDE, for instance, they have some station that will have data. Usually, EBA will have information on stops, for example, and then like this week or so on, we'll have more information about the machine itself. So it would be both. But in some instances, they also have third party equipment, for example, to do what is it called? Oh, no, not the words. But the leakage testing, they have extra equipment outside. In Oskar Shamm, they use, for example, also spectrograms to measure like vertical welds and stuff like this. So it will be also some equipment that is storing data somewhere else. It will be all types of data that can be used to support the line. Because EBA doesn't have exactly what kind of stop or the reason for a stop is. It's up to the operator to choose what the problem is. So to know that you must go into the PLC for the station or from the RGB system, for instance, to know exactly what kind of sensor or where in the program is stopped to have the detail. Yes. So when you go on, you are not doing that one, that deep level. Really, it doesn't. It depends. Some stations. Yes, some. No, the things that we're only taking three small cases to work on. We will not do everything else for this case. But in theory, like maybe I didn't say it very well at the beginning, but the idea of this project was to be exploratory at the beginning and very generalizable. So we are not really we don't really want to only focus on one thing. Idea is that we tackle data as a unit and say, how do you handle it in general? And then there will be very specific things that you need to do for getting it outside of DITRICK or getting it outside of EBA or outside of SQL or outside of whatever. And that will be very case based. I think it's potentially there can be some methods later on built for each of these maybe things that repeat across units. But we are not working on that yet. So it's just a project for troubleshooting for one station or so. Yeah. This one. So it's not in general that you collect all the data and then you see what you want to look at later on. No, I think we are working a little bit different. Actually, we're doing more like a problem based. So we have a lot of stops here. Can we do something about it? Yeah, because in connecting machines to a system, we or we want to connect more and more. But then we create a lot of data. And what should we do with all the data? That's a huge question because we are collecting data today, but no one is working with it. That one. Just for quality, for instance, we have not runner tools, tools, tools, not eight that we collect all the torques values. Yes. No one is looking at that one. Yes. And that is true. And we have also noticed that in some other instances also with tightening, but we also have noticed, for example, with leakage tests, they only look at it. If it's OK or not at the moment, but there is no one looking historically or in a time series of if something is happening. Yes. And in some instances, it is very difficult to really from just if you are like a data specialist to really say you should do this or that. Usually the value of the thing comes from the people that have a lot of domain knowledge. So if you are working on the line, you are the one that knows what potentially could be good to do. Or like if you are a specialist in this tightening state tightening station, you know, oh, but it would be super interesting if we see, you know, peaks of torque or something like that, because that would mean it's or why. Yeah, so it's very domain based. I'm not so sure if there can be a generalizable thing. Of course, if it's a process I repeated many times, then yes. But if it's a very specific process or a very specific station, then that's hard to repeat it. Maybe what there was we need to what we can generalize is how to treat, you know, data itself. Like, yeah, what analysis you can do. What I'm uploading. How can you predict things? And that is more generalizable. Yeah, I know I have worked a lot with that one. Last 23 years, I've looked at data also collect data go out to the machine with a USB memory and put it in the computer and use Excel just to get it. See how the trend are. And we find a lot of issues when we start to doing that. The quality got much, much better. But we are not doing that today. Even if we have all the tools, but it's not automatically generating in the computer. And I think that's the problem today. Yes, exactly. So it just I love that you said that because it is a little bit what you just mentioned. It summarizes these categories that we mentioned. We don't have the tools that do this automatically for us. We copy paste a lot. We don't have the competence to analyze it in many instances. Or maybe it's one person or two per unit that can do it. And then three, we don't have the the custom or the culture of just doing it. And when you start doing it, you find a lot of defects and then it's like, oh, we could improve this or that and so on. Yes. Yes. So I think it's really important that we start to work with that one also, just not connect, collect all the data. What should we do with all the data? For if we're not working with that data, it's just cost money for us. Just to connect it. Yeah. How do you start it? Like, how do you start building this culture of data driven? Because at the beginning, it's very difficult. If you come to a person that is not used to working with this, maybe you said you worked 20 years with if you're not doing it earlier, you're just going there using your lifting equipment or buying this equipment. You don't really know anything about this or not so in contact. So I think one idea is to have like an early adoption where, you know, people get to see some graphs, analyze some past examples, see the value out of it and then try to extrapolate this and build it. Bring it into your day to day. Like, think about how you could apply this into your day to day. Another thing is maybe having tools or having the competence to use tools that can support you with this. I know that's kind of has a good, good. So where is it called? Good. That's in the machining units. There is also mini tab. Some people use it for statistical analysis. Excel is also something, you know, open source things. So it's like Python and these data science libraries. So bringing a little bit of this competence and enthusiasm, people can also maybe support in working with this because I feel also it's very difficult for a special domain specialist to say, oh, we should collect that or not collect that if they also don't have the whole picture of how can we use it later. But I know that's kind of why we like to have this discussion to understand what you've been doing because we know about this project who's here, but we don't really know. How you work and not nor really divisions. Do we do we, as if we say the organization, we would like to create this culture. Then how do we do this? I mean, to foster. Extended use of the organization. I think the answer is quite easy. Yes. But then we should do it together in a good way. And what should that, how should that be done? And that is not easy. But yeah. Yes. And in the area of competence, Maria, sorry, Mathias is now leading this also AD to bring, we're going to work a little bit on two things. One is now we're working on building some workshops, doing some workshops with the units to bring them a little bit closer to these tools and how you can analyze it and so on. A bit hands on. We're trying it out with three units. We're doing it with the E. DT and the MS. Maybe you can just. Yeah. Yeah. So we're trying to tackle the awareness of the possibilities with data and what you can use it for and taking another little step into actually teaching. How do you hands on use a couple of tools in actually solving some of the problems that you have in your own unit, just to get people excited and have a little bit. Of knowledge to be able to take these first steps. And then the idea is that in the second half of this year, towards the end of the year, put these people together in one network so that people who are starting to work with data within production and logistics, they have like minded people to turn to. So they're only a network of we are doing the same thing. We are in the same boat. And I think the shape of that network is loose. We don't know. Maybe it's just the teams channel at the beginning where people can just ask questions of the same style and see what they're doing and so on. Let's see, because just yet another network. It was always the same question. I think there is a network between M. A. D. T. M. Is it the M or some? I think it's three different periods that they are working with data. How should they collect data? How should they analyze it? And how should they visualize it for the production? And you won Norlin from Emmy is working with that one. I don't know if you have contact with him. No, but I write down his name. Well, perhaps I should invite him more without the meeting so he could present what they have done. Yes, what is true is that. And of course, it's also where it's right. And many of the units like the X, I think probably was or maybe DT were like pioneers in trying to because they have their lines connected first, so to say. So we're like the first in building like dashboards that they use on a daily basis in their units. So maybe they also have some communication between each other, but many of these units finish or like ended up in the we build a dashboard. And then stop. Yes, I think in many cases, so that's what are nice. But what are you going to have a person all the time looking at the dashboard? Because also, if you have hundreds of machines, it doesn't make a lot of sense with a little thing. What you need is to build like action triggers that trigger things to happen when certain things that happen, certain levels of your data or whatever. And I think that's the we are very young and I don't think we do a lot of it in piano at least. If anything at all. I'm working now in a project that's the. We were building a. Well, a machine learning algorithm to. Propose like a thickness for a certain part that they need. The shin. But they have a lot of problems currently there and they do not solve it with traditional methods and they asked if we could maybe explore machine learning and there we're trying to implement it into the line. So those are, for example, examples of extra step also, right? You're not only collecting data, but then you're it's doing something for you. I heard of that project yesterday. Yes. Nice. So what are next steps? So we will now in June, May and June do these workshops. It's like three per unit. So it's a general workshop of two hours or one and a half hours and very general like more inspiration second. And that one we can also over time in the future, maybe make it like a digital thing that people can also look at in what is it about LXP. Yeah. And you're learning or I think it also nice to have it physically because then people get more enthusiastic about being able to ask questions and so on. But we could also like tweak it over time and now we just did a first version will change it a little bit now for a second time and we improve overtime and then if we also have more standard methods we can also present. The second workshop is two to three hours and it's like the. Very. Basic. Starting the use of tools and we're going to use Python in these instances and then this third workshop is four hours and in that we haven't run that yet. But that one would be hands on application of what we learned in lesson and a workshop one and two. So here we have learned how to use some tools. We have learned a little bit about what the purpose with data is and we hopefully have data from that unit in front of us and we do some work. And we do some analysis together with some graphs. We show you what you should look at. You know mean whatever like some statistics and then show that showcase a little bit of what machine learning is about. It also very intro to it. But not trying to motivate a little bit people and see what the what the possibilities for and we will run these three for each of the units until July. Yeah. Q2 out. Exactly. And then let's see. All right. The food first. Yeah. Which units have you focused on here. Maybe you said it already but the E D T and M S. It was a little bit random selected like we wanted to pilot it a bit. So we'll just see. Ms has no production now. No. So it's a good time. Okay. It's a good time. Yeah. Yes. And just to clarify. Mattias you will take over Jose this role or what's the. No I don't think I would take over. Jose is working with data science but I am running this AD for having workshops setting up this network. But then the data team or the experts and performing workshops and all the folks behind it. The data team from virtualization. From the lab. So Jose made that a little bit fresh. Yeah. Yeah. Okay. Yeah. Yes. And there will be I guess a substitute for me hired soon. But my dear, this doesn't say like the pro-ego leader and coordinator for this. So you can't work with these things trying to put things together. But if I understand correct this is kind of an approach to. Lift the awareness for this. Yeah. For the specific needs for that specific unit. Yes. A little bit for the unit because we touch some of their data in particular but also in general about how you should use. How do you approach a data set or something. You know, they can set you up data. Whatever. And in fact for the training the initial sessions we use things that have nothing to do with the unit. It will be in the last session that we touched things with the unit. So we use some data from the sinking of the Titanic and some data from the weather in Scandinavia. So it's just like you know it's also a little bit of understanding how data works is that it's numbers. So it doesn't really matter where it comes from. If you understand how to handle it it's then you could touch anything. So that's also a little bit of the goal of this. Yeah. I think that's that's that's interesting. What do you think should. Yeah. I really would like to see the results of it because we must work more with data with the correct data that could give back some money also. Yeah. But then we have to lift the general awareness in the units in the company on in this topic. It cannot be you me nor you in the lab pointing the finger. You need to use data. We need to show them and help them to show them. This is a way and I think we need to or I would like to not saying who not saying when not saying exactly how. But try to create some common methods as you said as well. We can have well this is the sconia way that we that we propose when you are to collect data. When you are to maintain moving format data when you are to analyze data. I understand we're not there yet but. Yeah. Yes. I think it also. You know a big every unit as you well know it's a little bit is a federative approach. We have their own small government. It is also a bit on their shoulders to invest in competence for this so that they know if the leaders believe that there's value in it. They can invest the correct resources into getting the correct data like you say show or using the things that they bring value for the buck. That we bring back money. Yeah. So. But we can assist them in taking that decision. Exactly. So it's a lot of things coming together one is we need to help the the workers actual people doing the work build up competence. Maybe then we get some that are more interested. We know we get a little bit of more interest and push for from them. We then help also the steering group by you know how can we talk about data. What value does it bring back showcasing some good examples for instance. And then also work on the tools. What tools do we have. How can we bring it. How can we have better tools that support us in the way we need. And so. So it's a lot of small things coming together. I think it would be really good if we could work together with me also to support. They will have huge problem to start up the production. And I think with data we could help them also. Yes. The that is we're very happy to do that. I would say. Sadly in many instances this is a little bit about connection sometimes right. If you have for example the lab has couldn't right now very good connection with some units and then they are the first that always say oh yes we are in. So then they're first to jump ship but we we love all units so we will have. Yeah. Yeah. I mean also connecting with MIM to see because they have taken an approach to how should they work with data and trying to learn from them. How they done it to see maybe trade trade to speak of Don Scarnia. Maybe there is some synergies to use here. It has this data production lab or whatever in Munich. They have I think 120 data scientists sitting in a building there doing things. So it's also like you know there's a lot of talent distributed through Volkswagen. This is central Volkswagen concern. So I think it is nice maybe that we can learn from others how they are doing it and maybe also even via lighthouse. Because I think not other other brands are not better than us. So maybe we can even be the leaders in some area and pave the way. I think that's cool. And on top of that something we have not mentioned is. Like the area of data analyst automation engineer and data scientist machine learning. It's very hot topics very attractive for people coming out of university for example or people in the early years of their careers. So it's also very nice if you have nice jobs in that area. It is a very nice way to attract new talent for Scarnia. Yeah but it must also bring back some money. Yeah we cannot just analyze without getting anything back to production. In the end it's all about getting better productivity in the production. That's what it is in the end. Yes. Yeah. Even it's fun with data. Yeah but I think we always are. There is always a challenge finding the correct employees with the correct competence. And this could be a potential to lift Scarnia a bit higher on that. In that demand. In that way as well. To be active in this area. But sure. What the value has to be there all the time. The question what is the value has to be there all the time. We have also built some. Like one page for example if you start a data project the things you should look at. And as we always like the first thing is what is the like maybe not the business case but it was a value return. So what are you trying to do. It's not about building a dashboard for just building a dashboard. But oh I want to be the dashboard because it's very important that we monitor the health of this compressor. Because if the compressor stops whatever. OK then you're already preventing stops. So that is the value that you're bringing right. Or we invest in this camera to increase quality and then we have traceability also. So the value is you have traceability and you increase your quality. So it's very important that we always have this behind any reasoning we do. Yeah exactly. OK. Nice. You talk about the data team in the lab. Who is kind of. Who is managing this kind of prioritizing. How do we work. We do weekly follow ups and monthly. So the same sprint planning. And it's a little bit based on what's the operations team in this more factory think is important. Operations team is Matias team David. Darby and Marion. So like the managing team. And it's a little bit at the same flow with other projects in this. And in the data team currently. We are quite democratic. So there's no one really leading it. Everyone is doing their own things. But let's say of that team. It's mostly me and mentally working full time because Thomas and Virg are part time. Yeah. Yeah. No I get it. But kind of like how. Yeah. Yeah. If today was to take your approach to focus more on method development perhaps. Yes. For understand how you work. But that is kind of a democratic process. But yeah. Not the ESL and the team. Yeah. Sure. I mean like starting any work in the lab. Yeah. Just hang out to me or James Sandin in the inbox if you don't want to talk to us. Yes. Maybe you prefer the inbox. No it's good. Because I mean it's not clear. From my perspective exactly the outcome from this meeting. But I think I have got a much better understanding now what you do. And I think you understand our approach as well. I don't know what's the next step we should be for this for us for the four of us. What do you think? We have follow up after these workshops have been done only for the area of like competence and general understanding of how we are the feedback we got back from the units and maybe I will probably not be anymore here when that is done. But just to have a follow up with how we do continue that later on. Right. If we adapt them if it makes sense to do more of them and so on. Also in June. So my idea now is to publish two articles about this data driven line to share in P&L. One is like with the findings that we had until the middle phase and the other one is to present a little bit the results of this smaller breaks that we're tackling. And try to potentially try to generalize a little bit out of it you know what methods we use and so on. So that's also maybe something to discuss in a follow up. I think that's good. And I mean, if do you want to be in any of these workshop sessions to just hear what. We are sending and how the peer use are receiving it and what questions arise from them. It's. It would be really interesting to be in one of them. If I have time to do it. I'm not sure but. Yeah, but I think I fly on the wall would be great. Yeah, I can send an invite for one of the sessions and you get a feel for what's happening. Yeah, please do. That's good. And I mean, we have complex and I mean now we talk about me, but. Within our organization we have good context to all units. It's just a matter of how we like to approach. Maybe this approach with the three sessions is the best one. Then we can together assist you or together we can create the. Contact to all units. Maybe all cannot say yes, but we can invite all the units. Or we see some some other way is preferred than we together can identify that. I think there is some way forward. Why me and Cheryl can assist more. Yeah, yes. But good, maybe it's from my perspective difficult to know when you're finalize those meetings. So if you materials can send invitation for a follow up meeting. If it's before or after vacation, but somewhere there. Yeah. Let's see how it feels when how ready to go to draw the conclusions before vacation. Yeah, because running that mountain like lost of you. So maybe if we can finish up the last days of July or first days of July. Yeah, yeah, you decide we have our calendars. That would be great. And then we can continue the front from that from those results. Yeah, that's good. That's good. Good, anything more so. Yeah, I was curious curious about the. The project you have that you want to record is from such a session. Oh yeah, so I am doing. I got inspired by. Some person that was doing some transcription of notes, so I have investigated three things. One is. You know, you record the meeting, I extract the audio of the meeting. I will send this into a transcription bot that is called Whisper. It's the best transcription. Model existing in the world and it's for free. It's free. And I have I have it set up in my laptop. I will get a transcript from it. I will divide it in small pieces and then I will send this to chat GPT asking it to this automatically. To summarize for me, give me the top five action points. It comments about the discussion and so on. So I can I will share the results with you later. Yeah, that would be fun to see how it goes. For now, I think my limit is I think because I think the chat GPT API has maximum 2000 words that can go in. Probably we will have more than 2000 words. So I need to see maybe I just take the first half or something like that. And then you can see the results because it will be interesting. Yeah, we're talking about that now when the meeting finishes. Frederick, you can give me access to download the video, please. Yeah, then I will then I can send it a bit later today. Yeah, I have all the components ready. Now I'm going to test it, call the components and I will build just like a script that runs all the components at once. So I just drag my file somewhere and then I get it directly into my notes. So that's the goal. Use notion that is a notebook, some notebook thing so I can show you later how it looks. Yeah, fun. Yes. OK, guys, thank you very much. Great. Thank you. Thank you. Bye bye. See you. Bye bye. Bye bye.