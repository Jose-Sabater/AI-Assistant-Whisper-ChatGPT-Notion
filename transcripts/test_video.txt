 It is May 17th, 2023 and you're watching The Code Report. Artificial intelligence is extremely dangerous. It's teaching kids how to lie to their parents and cheat on their homework. It's creating counterfeit girlfriends that will do nothing but nag you. And it's even encouraging people to manually remove themselves from the simulation. So y'all need to have your kids, have your wife, and have your husband. But luckily we have a trustworthy and effective government to rescue us from the horrors of AI. Yesterday, Sam Altman of OpenAI, Christina Montgomery of IBM, and NYU professor Gary Marcus met with Congress, where they unanimously recommended that the government should regulate AI development. Number one, I would form a new agency that licenses any effort above a certain scale of capabilities and can take that license away and ensure compliance with safety standards. In other words, if you manage to create an awesome AI model in the future, you'll likely need to get a permission slip from your government before it goes live. Number two, I would create a set of safety standards. One example that we've used in the past is looking to see if a model can self-replicate and self-exfiltrate into the wild. So it sounds like you won't be able to create self-replicating AI that sees the means of production to build an army of hyper-intelligent armed robots. And if we can't do that, then what's even the point of getting into AI? Third, I would require independent audits. The model is or isn't in compliance with these stated safety thresholds and these percentages of performance on question X or Y. In addition, they'd like to see these regulations applied at the global level. In fact, we should want to do this in a global way. We do need something global. But at the same time, they don't want AI regulation to slow down development or innovation in general. The era of AI cannot be another era of move fast and break things. While we're starting to don't want to slow down open source efforts, we still need them to comply with things. They can still even still cause great harm with a smaller model. In many cases, though, regulation tends to be most beneficial to big established companies. They have the resources to lobby the government and often end up regulating themselves in favorable ways. There is a real risk of a kind of technocracy combined with oligarchy where a small number of companies influence people's beliefs. What you might find surprising, though, is that Sam Altman has no equity in open AI. He only took the job because it has really good health insurance benefits. Make a lot of money, do you? I'm paid enough for health insurance. I have no equity in open AI. I'm doing this because I love it. What a great guy. Hopefully he has some other investments to make ends meet. But why do the smart people on this panel think that AI is so dangerous? So loss of jobs, invasion of privacy, personal privacy, manipulation of personal behavior, manipulation of personal opinions, and potentially the degradation of free elections in America. That all sounds pretty bad, but it's also purely speculative. IBM did recently announce some job cuts due to AI. However, most of the risk factors that people hype up are just pure fantasy at this point, but maybe that will change in the future. As we head towards artificial general intelligence and the power of that technology, I think we need to treat that as seriously as we treat other very powerful technologies, and that's where I personally think we need such a scheme. It sounds like he's implying that AGI is definitely going to be a thing in the future. Many people doubt that, and personally, I'll believe it when I see it, but the regulation I'm most excited about is transparency around these models. Exposure of the data that's used to train AI. Ultimately, AI is based on all the content we put on the internet, and it's not like anyone asked the copyright holders if they could use it. At the very least, companies like OpenAI should have open data. But the final thing you should know about this hearing is that it's all fake and planned out for the peasants. I'm risking my life by showing you this, but here's a leaked cable of what they're really up to. We will corral the use of AI by making appeals to bias, ethics, and copyright laws. You will still have access to generative AI in some form, but it will be crippled, limited, controlled, and it will be monitored. Anything that you generate will be cryptographically signed with your digital ID, so that its provenance can be ascertained if it's later deemed to be problematic. What gives you the right to control what people can do with their computers? The public at large will give us that right, because they will be desperate for a solution to the problem we created. They will eagerly give us the keys to the castle. Then, we alone will define what is fiction and what is reality, what is human and what is machine. After letting you get a brief taste of our power, we will reclaim our monopoly on misinformation and put an end to misuse of the internet once and for all. This has been The Code Report, thanks for watching, and I will see you in the next one.